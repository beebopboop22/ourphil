name: Scrape Stateside Live

on:
  schedule:
    # Runs every day at 3:10 AM UTC
    - cron: '10 3 * * *'
  workflow_dispatch:

concurrency:
  group: scrape-statesidelive
  cancel-in-progress: false

jobs:
  scrape:
    name: Scrape Stateside Live Events
    runs-on: ubuntu-latest
    env:
      # Add these in your repo Settings → Secrets and variables → Actions
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install supabase requests beautifulsoup4 python-dotenv
          fi

      - name: Run Stateside Live scraper
        run: python scripts/scrape-stateside-live.py
